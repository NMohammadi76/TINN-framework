{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Theoretical-Informed Neural Network (TINN) for Cognitive Model Parameter Estimation\n",
        "from Experimental Reaction Time Data\n",
        "\n",
        "Q1 Journal Paper: Multi-condition parameter estimation using physics-informed deep learning\n",
        "Experimental data from FDBNCRW2008 dataset with speed, neutral, and accuracy conditions\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import scipy.optimize\n",
        "import pandas as pd\n",
        "from scipy.stats import gaussian_kde\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# =============================================================================\n",
        "# Configuration\n",
        "# =============================================================================\n",
        "\n",
        "# TINN Architecture\n",
        "NUM_HIDDEN_LAYERS = 4\n",
        "NUM_NEURONS_PER_LAYER = 30\n",
        "ACTIVATION = 'tanh'\n",
        "KERNEL_INITIALIZER = 'glorot_normal'\n",
        "OUTPUT_DIM = 3  # For three experimental conditions\n",
        "\n",
        "# Training Parameters\n",
        "NUM_EPOCHS = 20000\n",
        "LEARNING_RATE_SCHEDULE = [1000, 15000]\n",
        "LEARNING_RATES = [0.05, 0.001, 0.0005]\n",
        "\n",
        "# Domain Parameters\n",
        "THRESHOLD = 1.0\n",
        "N_COLLOCATION = 100\n",
        "N_BOUNDARY = 500\n",
        "N_INITIAL = 50\n",
        "\n",
        "# =============================================================================\n",
        "# TINN Architecture for Multi-Condition Cognitive Modeling\n",
        "# =============================================================================\n",
        "\n",
        "class TINN_CognitiveNet(tf.keras.Model):\n",
        "    \"\"\"\n",
        "    Theoretical-Informed Neural Network for cognitive model parameter estimation.\n",
        "    Simultaneously models three experimental conditions with separate noise parameters.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, lb, ub, output_dim=3, num_hidden_layers=5,\n",
        "                 num_neurons_per_layer=50, activation='tanh',\n",
        "                 kernel_initializer='glorot_normal', **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "\n",
        "        self.num_hidden_layers = num_hidden_layers\n",
        "        self.output_dim = output_dim\n",
        "        self.lb = lb\n",
        "        self.ub = ub\n",
        "\n",
        "        # Neural network architecture\n",
        "        self.hidden_layers = [\n",
        "            tf.keras.layers.Dense(\n",
        "                num_neurons_per_layer,\n",
        "                activation=tf.keras.activations.get(activation),\n",
        "                kernel_initializer=kernel_initializer\n",
        "            ) for _ in range(self.num_hidden_layers - 1)\n",
        "        ]\n",
        "        self.final_hidden = tf.keras.layers.Dense(\n",
        "            num_neurons_per_layer, activation='softplus'\n",
        "        )\n",
        "        self.output_layer = tf.keras.layers.Dense(output_dim)\n",
        "\n",
        "        # Cognitive model parameters\n",
        "        self.drift_param = self.add_weight(\n",
        "            name=\"drift_param\", initializer=\"ones\", trainable=True, dtype=tf.float32\n",
        "        )\n",
        "        self.noise_speed = self.add_weight(\n",
        "            name=\"noise_speed\", initializer=\"ones\", trainable=True, dtype=tf.float32\n",
        "        )\n",
        "        self.noise_neutral = self.add_weight(\n",
        "            name=\"noise_neutral\", initializer=\"ones\", trainable=True, dtype=tf.float32\n",
        "        )\n",
        "        self.noise_accuracy = self.add_weight(\n",
        "            name=\"noise_accuracy\", initializer=\"ones\", trainable=True, dtype=tf.float32\n",
        "        )\n",
        "        self.non_decision_param = self.add_weight(\n",
        "            name=\"non_decision_param\", initializer=\"ones\", trainable=True, dtype=tf.float32\n",
        "        )\n",
        "\n",
        "        # Training history\n",
        "        self.drift_history = []\n",
        "        self.noise_speed_history = []\n",
        "        self.noise_neutral_history = []\n",
        "        self.noise_accuracy_history = []\n",
        "        self.non_decision_history = []\n",
        "\n",
        "    def call(self, X):\n",
        "        \"\"\"Forward pass through the network.\"\"\"\n",
        "        Z = X\n",
        "        for layer in self.hidden_layers:\n",
        "            Z = layer(Z)\n",
        "        Z = self.final_hidden(Z)\n",
        "        return self.output_layer(Z)\n",
        "\n",
        "    @property\n",
        "    def drift_rate(self):\n",
        "        \"\"\"Get positive drift rate using softplus.\"\"\"\n",
        "        return tf.nn.softplus(self.drift_param)\n",
        "\n",
        "    @property\n",
        "    def non_decision_time(self):\n",
        "        \"\"\"Get non-decision time with sigmoid scaling.\"\"\"\n",
        "        return tf.math.sigmoid(self.non_decision_param)\n",
        "\n",
        "# =============================================================================\n",
        "# TINN Cognitive Model Solver\n",
        "# =============================================================================\n",
        "\n",
        "class TINN_CognitiveSolver:\n",
        "    \"\"\"\n",
        "    Solver for cognitive model parameter estimation using TINN.\n",
        "    Handles multiple experimental conditions with correct/incorrect responses.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, model, collocation_points, reaction_times_dict):\n",
        "        self.model = model\n",
        "        self.t = collocation_points[:, 0:1]\n",
        "        self.x = collocation_points[:, 1:2]\n",
        "        self.reaction_times = reaction_times_dict\n",
        "\n",
        "        # Training history\n",
        "        self.loss_history = []\n",
        "        self.iteration = 0\n",
        "        self.min_reaction_time = 0.0\n",
        "\n",
        "    def compute_pde_residuals(self):\n",
        "        \"\"\"\n",
        "        Compute PDE residuals for all three conditions using automatic differentiation.\n",
        "        \"\"\"\n",
        "        with tf.GradientTape(persistent=True) as tape:\n",
        "            tape.watch(self.t)\n",
        "            tape.watch(self.x)\n",
        "\n",
        "            # Compute solutions and gradients for all conditions\n",
        "            s = self.model(tf.stack([self.t[:, 0], self.x[:, 0]], axis=1))\n",
        "            u_speed = s[:, 0:1]\n",
        "            u_neutral = s[:, 1:2]\n",
        "            u_accuracy = s[:, 2:3]\n",
        "\n",
        "            u_speed_x = tape.gradient(u_speed, self.x)\n",
        "            u_neutral_x = tape.gradient(u_neutral, self.x)\n",
        "            u_accuracy_x = tape.gradient(u_accuracy, self.x)\n",
        "\n",
        "        u_speed_t = tape.gradient(u_speed, self.t)\n",
        "        u_speed_xx = tape.gradient(u_speed_x, self.x)\n",
        "        u_neutral_t = tape.gradient(u_neutral, self.t)\n",
        "        u_neutral_xx = tape.gradient(u_neutral_x, self.x)\n",
        "        u_accuracy_t = tape.gradient(u_accuracy, self.t)\n",
        "        u_accuracy_xx = tape.gradient(u_accuracy_x, self.x)\n",
        "\n",
        "        del tape\n",
        "\n",
        "        # Return residuals for all conditions\n",
        "        return (\n",
        "            self._pde_residual(u_speed, u_speed_t, u_speed_x, u_speed_xx, self.model.noise_speed),\n",
        "            self._pde_residual(u_neutral, u_neutral_t, u_neutral_x, u_neutral_xx, self.model.noise_neutral),\n",
        "            self._pde_residual(u_accuracy, u_accuracy_t, u_accuracy_x, u_accuracy_xx, self.model.noise_accuracy)\n",
        "        )\n",
        "\n",
        "    def _pde_residual(self, u, u_t, u_x, u_xx, noise_param):\n",
        "        \"\"\"Fokker-Planck equation residual.\"\"\"\n",
        "        return u_t + self.model.drift_rate * u_x - 0.5 * (noise_param**2) * u_xx\n",
        "\n",
        "    def loss_function(self, boundary_data, boundary_values):\n",
        "        \"\"\"\n",
        "        Comprehensive loss function combining PDE residuals and data fitting.\n",
        "        \"\"\"\n",
        "        # PDE residual losses\n",
        "        residual_speed, residual_neutral, residual_accuracy = self.compute_pde_residuals()\n",
        "        pde_loss = (\n",
        "            tf.reduce_mean(tf.square(residual_speed)) +\n",
        "            tf.reduce_mean(tf.square(residual_neutral)) +\n",
        "            tf.reduce_mean(tf.square(residual_accuracy))\n",
        "        )\n",
        "\n",
        "        # Boundary condition losses\n",
        "        u_pred_initial = self.model(boundary_data[0])\n",
        "        initial_loss = tf.reduce_mean(tf.square(boundary_values[0] - u_pred_initial))\n",
        "\n",
        "        u_pred_boundary = self.model(boundary_data[1])\n",
        "        boundary_loss = tf.reduce_mean(tf.square(boundary_values[1] - u_pred_boundary))\n",
        "\n",
        "        # Data fitting losses for all conditions\n",
        "        data_losses = self._compute_data_fitting_losses()\n",
        "\n",
        "        # Combined loss\n",
        "        total_loss = 1.0 * (pde_loss + initial_loss + boundary_loss) + data_losses\n",
        "\n",
        "        return total_loss\n",
        "\n",
        "    def _compute_data_fitting_losses(self):\n",
        "        \"\"\"\n",
        "        Compute data fitting losses for all experimental conditions.\n",
        "        \"\"\"\n",
        "        # Update minimum reaction time across all conditions\n",
        "        all_times = []\n",
        "        for key in self.reaction_times:\n",
        "            all_times.extend(self.reaction_times[key])\n",
        "        self.min_reaction_time = min(all_times) if all_times else 0.1\n",
        "\n",
        "        total_data_loss = 0.0\n",
        "\n",
        "        # Speed condition (correct and incorrect)\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['speed_correct'], self.model.ub[1], 0, True\n",
        "        )\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['speed_incorrect'], self.model.lb[1], 0, False\n",
        "        )\n",
        "\n",
        "        # Neutral condition (correct and incorrect)\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['neutral_correct'], self.model.ub[1], 1, True\n",
        "        )\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['neutral_incorrect'], self.model.lb[1], 1, False\n",
        "        )\n",
        "\n",
        "        # Accuracy condition (correct and incorrect)\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['accuracy_correct'], self.model.ub[1], 2, True\n",
        "        )\n",
        "        total_data_loss += self._compute_condition_loss(\n",
        "            self.reaction_times['accuracy_incorrect'], self.model.lb[1], 2, False\n",
        "        )\n",
        "\n",
        "        return total_data_loss\n",
        "\n",
        "    def _compute_condition_loss(self, reaction_times, boundary_position, output_index, upper_boundary):\n",
        "        \"\"\"\n",
        "        Compute loss for a single condition.\n",
        "        \"\"\"\n",
        "        if len(reaction_times) == 0:\n",
        "            return tf.constant(0.0, dtype=tf.float32)\n",
        "\n",
        "        sorted_times = np.sort(reaction_times)\n",
        "\n",
        "        # Prepare time points for prediction\n",
        "        times_tensor = tf.constant(\n",
        "            sorted_times.reshape((len(sorted_times), 1)), tf.float32\n",
        "        )\n",
        "        adjusted_times = times_tensor - self.model.non_decision_time * self.min_reaction_time\n",
        "\n",
        "        # Compute predicted flux\n",
        "        predicted_flux = self._compute_boundary_flux(adjusted_times, boundary_position, output_index, upper_boundary)\n",
        "\n",
        "        # Empirical distribution using KDE\n",
        "        kde = gaussian_kde(sorted_times)\n",
        "        empirical_density = len(sorted_times) * kde(sorted_times)[:, np.newaxis] / len(sorted_times)\n",
        "        empirical_tensor = tf.convert_to_tensor(empirical_density, dtype=tf.float32)\n",
        "\n",
        "        if not upper_boundary:\n",
        "            empirical_tensor = -empirical_tensor\n",
        "\n",
        "        return tf.reduce_mean(tf.square(predicted_flux - empirical_tensor))\n",
        "\n",
        "    def _compute_boundary_flux(self, times_tensor, boundary_pos, output_index, upper_boundary):\n",
        "        \"\"\"\n",
        "        Compute flux at boundary using finite differences.\n",
        "        \"\"\"\n",
        "        batch_size = tf.shape(times_tensor)[0]\n",
        "\n",
        "        # Boundary points\n",
        "        x_boundary = tf.ones((batch_size, 1), dtype=tf.float32) * boundary_pos\n",
        "        X_boundary = tf.concat([times_tensor, x_boundary], axis=1)\n",
        "        p_boundary = self.model(X_boundary)[:, output_index:output_index+1]\n",
        "\n",
        "        # Points for derivative calculation\n",
        "        dx = 0.02 if upper_boundary else 0.05\n",
        "        offset = -dx if upper_boundary else dx\n",
        "\n",
        "        x_offset1 = tf.ones((batch_size, 1), dtype=tf.float32) * (boundary_pos + offset)\n",
        "        X_offset1 = tf.concat([times_tensor, x_offset1], axis=1)\n",
        "        p_offset1 = self.model(X_offset1)[:, output_index:output_index+1]\n",
        "\n",
        "        x_offset2 = tf.ones((batch_size, 1), dtype=tf.float32) * (boundary_pos + 2 * offset)\n",
        "        X_offset2 = tf.concat([times_tensor, x_offset2], axis=1)\n",
        "        p_offset2 = self.model(X_offset2)[:, output_index:output_index+1]\n",
        "\n",
        "        # Finite difference derivative\n",
        "        if upper_boundary:\n",
        "            p_x = (3 * p_boundary - 4 * p_offset1 + p_offset2) / (2 * dx)\n",
        "        else:\n",
        "            p_x = (-3 * p_boundary + 4 * p_offset1 - p_offset2) / (2 * dx)\n",
        "\n",
        "        # Get appropriate noise parameter\n",
        "        if output_index == 0:\n",
        "            noise_param = self.model.noise_speed\n",
        "        elif output_index == 1:\n",
        "            noise_param = self.model.noise_neutral\n",
        "        else:\n",
        "            noise_param = self.model.noise_accuracy\n",
        "\n",
        "        # Boundary flux\n",
        "        flux = self.model.drift_rate * p_boundary - 0.5 * (noise_param**2) * p_x\n",
        "\n",
        "        return flux\n",
        "\n",
        "    def compute_gradients(self, boundary_data, boundary_values):\n",
        "        \"\"\"Compute gradients of the loss function.\"\"\"\n",
        "        with tf.GradientTape() as tape:\n",
        "            loss = self.loss_function(boundary_data, boundary_values)\n",
        "\n",
        "        gradients = tape.gradient(loss, self.model.trainable_variables)\n",
        "        return loss, gradients\n",
        "\n",
        "    def train_step(self, optimizer, boundary_data, boundary_values):\n",
        "        \"\"\"Single training step.\"\"\"\n",
        "        loss, gradients = self.compute_gradients(boundary_data, boundary_values)\n",
        "        optimizer.apply_gradients(zip(gradients, self.model.trainable_variables))\n",
        "        return loss\n",
        "\n",
        "    def fit(self, boundary_data, boundary_values, epochs=1000):\n",
        "        \"\"\"Train the TINN model.\"\"\"\n",
        "        lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "            LEARNING_RATE_SCHEDULE, LEARNING_RATES\n",
        "        )\n",
        "        optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "        def training_step():\n",
        "            return self.train_step(optimizer, boundary_data, boundary_values)\n",
        "\n",
        "        print(\"Starting TINN cognitive model fitting...\")\n",
        "        start_time = time()\n",
        "\n",
        "        for epoch in range(epochs):\n",
        "            loss = training_step()\n",
        "            self._training_callback(epoch, loss)\n",
        "\n",
        "        training_time = time() - start_time\n",
        "        print(f'\\nTraining completed in {training_time:.2f} seconds')\n",
        "\n",
        "    def _training_callback(self, epoch, loss):\n",
        "        \"\"\"Training progress monitoring.\"\"\"\n",
        "        current_loss = loss.numpy()\n",
        "        drift = self.model.drift_rate.numpy()\n",
        "        noise_speed = self.model.noise_speed.numpy()\n",
        "        noise_neutral = self.model.noise_neutral.numpy()\n",
        "        noise_accuracy = self.model.noise_accuracy.numpy()\n",
        "        non_decision = self.model.non_decision_time.numpy() * self.min_reaction_time\n",
        "\n",
        "        # Store parameter history\n",
        "        self.model.drift_history.append(drift)\n",
        "        self.model.noise_speed_history.append(noise_speed)\n",
        "        self.model.noise_neutral_history.append(noise_neutral)\n",
        "        self.model.noise_accuracy_history.append(noise_accuracy)\n",
        "        self.model.non_decision_history.append(non_decision)\n",
        "\n",
        "        if epoch % 100 == 0:\n",
        "            print(\n",
        "                f'Epoch {epoch:05d}: Loss = {current_loss:10.8e}, '\n",
        "                f'Drift = {drift:10.8e}, '\n",
        "                f'Noise (S/N/A) = ({noise_speed:10.8e}/{noise_neutral:10.8e}/{noise_accuracy:10.8e}), '\n",
        "                f'Non-decision = {non_decision:10.8e}'\n",
        "            )\n",
        "\n",
        "        self.loss_history.append(current_loss)\n",
        "        self.iteration += 1\n",
        "\n",
        "# =============================================================================\n",
        "# Data Preparation and Visualization\n",
        "# =============================================================================\n",
        "\n",
        "def load_experimental_data(file_path):\n",
        "    \"\"\"Load experimental data from RData file.\"\"\"\n",
        "    try:\n",
        "        import pyreadr\n",
        "        result = pyreadr.read_r(file_path)\n",
        "        return result[\"data\"]\n",
        "    except ImportError:\n",
        "        print(\"pyreadr not available. Using synthetic data for demonstration.\")\n",
        "        return create_synthetic_data()\n",
        "\n",
        "def create_synthetic_data():\n",
        "    \"\"\"Create synthetic data for testing when real data is not available.\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_trials = 100\n",
        "\n",
        "    synthetic_data = {\n",
        "        'speed_correct': np.random.gamma(2, 0.3, n_trials) + 0.2,\n",
        "        'speed_incorrect': np.random.gamma(2, 0.4, n_trials) + 0.2,\n",
        "        'neutral_correct': np.random.gamma(2, 0.35, n_trials) + 0.2,\n",
        "        'neutral_incorrect': np.random.gamma(2, 0.45, n_trials) + 0.2,\n",
        "        'accuracy_correct': np.random.gamma(2, 0.4, n_trials) + 0.2,\n",
        "        'accuracy_incorrect': np.random.gamma(2, 0.5, n_trials) + 0.2\n",
        "    }\n",
        "\n",
        "    return synthetic_data\n",
        "\n",
        "def prepare_training_data(reaction_times_dict, threshold=THRESHOLD):\n",
        "    \"\"\"Prepare domain and training data for TINN.\"\"\"\n",
        "    # Define domain boundaries\n",
        "    xmax = threshold\n",
        "    xmin = -xmax\n",
        "\n",
        "    # Find maximum reaction time\n",
        "    max_time = 0\n",
        "    for key in reaction_times_dict:\n",
        "        if len(reaction_times_dict[key]) > 0:\n",
        "            max_time = max(max_time, max(reaction_times_dict[key]))\n",
        "\n",
        "    lb = tf.constant([0.0, xmin], dtype=tf.float32)\n",
        "    ub = tf.constant([max_time, xmax], dtype=tf.float32)\n",
        "\n",
        "    # Collocation points\n",
        "    tspace = np.linspace(lb[0], ub[0], N_COLLOCATION + 1)\n",
        "    xspace = np.linspace(lb[1], ub[1], N_COLLOCATION + 1)\n",
        "    T, X = np.meshgrid(tspace, xspace)\n",
        "    X_grid = np.vstack([T.flatten(), X.flatten()]).T\n",
        "    collocation_points = tf.constant(X_grid, dtype=tf.float32)\n",
        "\n",
        "    # Boundary and initial conditions\n",
        "    boundary_data, boundary_values = _prepare_boundary_conditions(lb, ub)\n",
        "\n",
        "    return collocation_points, boundary_data, boundary_values, lb, ub\n",
        "\n",
        "def _prepare_boundary_conditions(lb, ub, n_boundary=N_BOUNDARY, n_initial=N_INITIAL):\n",
        "    \"\"\"Prepare boundary and initial condition data.\"\"\"\n",
        "    # Initial condition (Gaussian distribution)\n",
        "    def initial_condition(x, delta=7.8e-2, x0=0.0):\n",
        "        return 1 / (2 * np.sqrt(np.pi * delta)) * tf.math.exp(-((x - x0)**2) / (4 * delta))\n",
        "\n",
        "    # Initial condition data\n",
        "    t_initial = tf.ones((n_initial, 1), dtype=tf.float32) * lb[0]\n",
        "    x_initial = np.linspace(lb[1], ub[1], n_initial - 1, dtype=np.float32)\n",
        "    x_initial = np.sort(np.concatenate([x_initial, [0.0]]))\n",
        "    x_initial = tf.constant(x_initial.reshape((n_initial, 1)), dtype=tf.float32)\n",
        "    u_initial = initial_condition(x_initial)\n",
        "    X_initial = tf.concat([t_initial, x_initial], axis=1)\n",
        "\n",
        "    # Boundary condition data\n",
        "    t_boundary = tf.random.uniform((n_boundary, 1), lb[0], ub[0], dtype=tf.float32)\n",
        "    x_boundary = lb[1] + (ub[1] - lb[1]) * tf.keras.backend.random_bernoulli(\n",
        "        (n_boundary, 1), 0.5, dtype=tf.float32\n",
        "    )\n",
        "    X_boundary = tf.concat([t_boundary, x_boundary], axis=1)\n",
        "    u_boundary = tf.zeros_like(x_boundary, dtype=tf.float32)\n",
        "\n",
        "    return [X_initial, X_boundary], [u_initial, u_boundary]\n",
        "\n",
        "def plot_training_convergence(solver):\n",
        "    \"\"\"Plot training convergence and parameter evolution.\"\"\"\n",
        "    fig, axes = plt.subplots(2, 2, figsize=(12, 8))\n",
        "\n",
        "    # Loss history\n",
        "    axes[0, 0].semilogy(solver.loss_history, 'k-', linewidth=2)\n",
        "    axes[0, 0].set_xlabel('Epoch')\n",
        "    axes[0, 0].set_ylabel('Loss')\n",
        "    axes[0, 0].set_title('Training Loss Convergence')\n",
        "    axes[0, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Drift rate convergence\n",
        "    axes[0, 1].plot(solver.model.drift_history, 'b-', linewidth=2)\n",
        "    axes[0, 1].set_xlabel('Epoch')\n",
        "    axes[0, 1].set_ylabel('Drift Rate')\n",
        "    axes[0, 1].set_title('Drift Rate Estimation')\n",
        "    axes[0, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    # Noise parameters convergence\n",
        "    axes[1, 0].plot(solver.model.noise_speed_history, 'r-', linewidth=2, label='Speed')\n",
        "    axes[1, 0].plot(solver.model.noise_neutral_history, 'g-', linewidth=2, label='Neutral')\n",
        "    axes[1, 0].plot(solver.model.noise_accuracy_history, 'b-', linewidth=2, label='Accuracy')\n",
        "    axes[1, 0].set_xlabel('Epoch')\n",
        "    axes[1, 0].set_ylabel('Noise Parameters')\n",
        "    axes[1, 0].set_title('Noise Parameters Estimation')\n",
        "    axes[1, 0].legend()\n",
        "    axes[1, 0].grid(True, alpha=0.3)\n",
        "\n",
        "    # Non-decision time convergence\n",
        "    axes[1, 1].plot(solver.model.non_decision_history, 'm-', linewidth=2)\n",
        "    axes[1, 1].set_xlabel('Epoch')\n",
        "    axes[1, 1].set_ylabel('Non-decision Time')\n",
        "    axes[1, 1].set_title('Non-decision Time Estimation')\n",
        "    axes[1, 1].grid(True, alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"tinn_cognitive_convergence.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# Main Execution\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function for TINN cognitive model fitting.\"\"\"\n",
        "    print(\"TINN Cognitive Model Parameter Estimation\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "    # Load experimental data\n",
        "    data_file_path = '.../FDBNCRW2008.RData'\n",
        "    experimental_data = load_experimental_data(data_file_path)\n",
        "\n",
        "    # Prepare reaction time data structure\n",
        "    reaction_times = {\n",
        "        'speed_correct': [],\n",
        "        'speed_incorrect': [],\n",
        "        'neutral_correct': [],\n",
        "        'neutral_incorrect': [],\n",
        "        'accuracy_correct': [],\n",
        "        'accuracy_incorrect': []\n",
        "    }\n",
        "\n",
        "    # Process experimental data (example for first subject)\n",
        "    if hasattr(experimental_data, 'subj'):\n",
        "        subjects = np.unique(experimental_data.subj)\n",
        "        if len(subjects) > 0:\n",
        "            first_subject = subjects[0]\n",
        "            for condition in ['speed', 'neutral', 'accuracy']:\n",
        "                sub_data = experimental_data.loc[\n",
        "                    (experimental_data.subj == first_subject) &\n",
        "                    (experimental_data.instruction == condition)\n",
        "                ]\n",
        "                reaction_times[f'{condition}_correct'] = list(\n",
        "                    sub_data.loc[sub_data.correct == True].RT\n",
        "                )\n",
        "                reaction_times[f'{condition}_incorrect'] = list(\n",
        "                    sub_data.loc[sub_data.correct == False].RT\n",
        "                )\n",
        "    else:\n",
        "        # Use synthetic data if experimental data not available\n",
        "        reaction_times = create_synthetic_data()\n",
        "\n",
        "    print(\"Data summary:\")\n",
        "    for key, values in reaction_times.items():\n",
        "        if len(values) > 0:\n",
        "            print(f\"  {key}: {len(values)} trials, RT range: {min(values):.3f}-{max(values):.3f}\")\n",
        "\n",
        "    # Prepare training data\n",
        "    collocation_points, boundary_data, boundary_values, lb, ub = prepare_training_data(reaction_times)\n",
        "\n",
        "    # Initialize TINN model\n",
        "    model = TINN_CognitiveNet(\n",
        "        lb, ub,\n",
        "        num_hidden_layers=NUM_HIDDEN_LAYERS,\n",
        "        num_neurons_per_layer=NUM_NEURONS_PER_LAYER,\n",
        "        activation=ACTIVATION,\n",
        "        kernel_initializer=KERNEL_INITIALIZER\n",
        "    )\n",
        "\n",
        "    # Initialize solver\n",
        "    solver = TINN_CognitiveSolver(model, collocation_points, reaction_times)\n",
        "\n",
        "    # Train model\n",
        "    solver.fit(boundary_data, boundary_values, epochs=NUM_EPOCHS)\n",
        "\n",
        "    # Display results\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(\"COGNITIVE MODEL PARAMETER ESTIMATION RESULTS\")\n",
        "    print(\"=\" * 60)\n",
        "    print(f\"Estimated drift rate: {model.drift_rate.numpy():.4f}\")\n",
        "    print(f\"Estimated noise (Speed): {model.noise_speed.numpy():.4f}\")\n",
        "    print(f\"Estimated noise (Neutral): {model.noise_neutral.numpy():.4f}\")\n",
        "    print(f\"Estimated noise (Accuracy): {model.noise_accuracy.numpy():.4f}\")\n",
        "    print(f\"Estimated non-decision time: {solver.model.non_decision_time.numpy() * solver.min_reaction_time:.4f}\")\n",
        "\n",
        "    # Generate plots\n",
        "    plot_training_convergence(solver)\n",
        "\n",
        "    print(\"\\nCognitive model fitting completed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "AJzFibPqTy_u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "76ENP3AoTzmW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}