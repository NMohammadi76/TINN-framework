{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "Theoretical-Informed Neural Network (TINN) for DDM model\n",
        "with Time-Dependent Drift and First Passage Time Analysis\n",
        "\"\"\"\n",
        "\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from time import time\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "import scipy.optimize\n",
        "\n",
        "# =============================================================================\n",
        "# Configuration and Constants\n",
        "# =============================================================================\n",
        "\n",
        "# Set data type\n",
        "DTYPE = 'float32'\n",
        "tf.keras.backend.set_floatx(DTYPE)\n",
        "\n",
        "# Physical parameters\n",
        "DELTA = 7.8e-2\n",
        "SIGMA = 1.0\n",
        "V0 = 0.3\n",
        "V1 = 0.4\n",
        "TAU0 = 0.8\n",
        "\n",
        "# Domain boundaries\n",
        "TMIN, TMAX = 0.0, 3.0\n",
        "XMIN, XMAX = -2.0, 2.0\n",
        "\n",
        "# Training parameters\n",
        "N_0 = 100    # Initial condition points\n",
        "N_B = 200    # Boundary condition points\n",
        "N_R = 5000   # Residual collocation points\n",
        "NUM_EPOCHS = 15000\n",
        "\n",
        "# Neural network architecture\n",
        "NUM_HIDDEN_LAYERS = 3\n",
        "NUM_NEURONS_PER_LAYER = 30\n",
        "\n",
        "# =============================================================================\n",
        "# Physics Definitions\n",
        "# =============================================================================\n",
        "\n",
        "def dirac_delta_function(x, delta):\n",
        "    \"\"\"Approximate Dirac delta function as a Gaussian distribution.\"\"\"\n",
        "    return 1 / (2 * np.sqrt(np.pi * delta)) * tf.math.exp(-((x - 0.0)**2) / (4 * delta))\n",
        "\n",
        "def time_dependent_drift(t):\n",
        "    \"\"\"Define time-dependent drift coefficient.\"\"\"\n",
        "    return V0 + V1 * (t / (t + TAU0))\n",
        "\n",
        "def initial_condition(x):\n",
        "    \"\"\"Define initial condition at t=0.\"\"\"\n",
        "    return dirac_delta_function(x, DELTA)\n",
        "\n",
        "def boundary_condition(t, x):\n",
        "    \"\"\"Define boundary condition.\"\"\"\n",
        "    n = x.shape[0]\n",
        "    return tf.zeros((n, 1), dtype=DTYPE)\n",
        "\n",
        "def pde_residual(t, x, u, u_t, u_x, u_xx):\n",
        "    \"\"\"Define the PDE residual (Fokker-Planck equation with time-dependent drift).\"\"\"\n",
        "    drift = tf.reshape(time_dependent_drift(t), [tf.shape(t)[0], 1])\n",
        "    return u_t + drift * u_x - 0.5 * SIGMA**2 * u_xx\n",
        "\n",
        "# =============================================================================\n",
        "# Data Preparation\n",
        "# =============================================================================\n",
        "\n",
        "def prepare_training_data():\n",
        "    \"\"\"Prepare initial, boundary, and collocation points for training.\"\"\"\n",
        "\n",
        "    # Domain bounds\n",
        "    lb = tf.constant([TMIN, XMIN], dtype=DTYPE)\n",
        "    ub = tf.constant([TMAX, XMAX], dtype=DTYPE)\n",
        "\n",
        "    # Initial condition data\n",
        "    t_0 = tf.ones((N_0, 1), dtype=DTYPE) * lb[0]\n",
        "    x_0 = np.linspace(lb[1], ub[1], N_0 - 1, dtype=DTYPE)\n",
        "    x_0 = np.asarray(list(x_0) + [0.0])  # Ensure point at x=0 is included\n",
        "    x_0 = tf.convert_to_tensor(x_0, dtype=DTYPE)\n",
        "    x_0 = tf.reshape(x_0, [N_0, 1])\n",
        "    u_0 = initial_condition(x_0)\n",
        "    X_0 = tf.concat([t_0, x_0], axis=1)\n",
        "\n",
        "    # Boundary condition data\n",
        "    t_b = tf.random.uniform((N_B, 1), lb[0], ub[0], dtype=DTYPE)\n",
        "    x_b = lb[1] + (ub[1] - lb[1]) * tf.keras.backend.random_bernoulli(\n",
        "        (N_B, 1), 0.5, dtype=DTYPE)\n",
        "    X_b = tf.concat([t_b, x_b], axis=1)\n",
        "    u_b = boundary_condition(t_b, x_b)\n",
        "\n",
        "    # Collocation points for PDE residual\n",
        "    t_r = tf.random.uniform((N_R, 1), lb[0], ub[0], dtype=DTYPE)\n",
        "    x_r = tf.random.uniform((N_R, 1), lb[1], ub[1], dtype=DTYPE)\n",
        "    X_r = tf.concat([t_r, x_r], axis=1)\n",
        "\n",
        "    # Collect all data\n",
        "    X_data = [X_0, X_b]\n",
        "    u_data = [u_0, u_b]\n",
        "\n",
        "    return X_r, X_data, u_data, lb, ub\n",
        "\n",
        "# =============================================================================\n",
        "# Neural Network Model\n",
        "# =============================================================================\n",
        "\n",
        "def create_model(num_hidden_layers=NUM_HIDDEN_LAYERS, num_neurons_per_layer=NUM_NEURONS_PER_LAYER):\n",
        "    \"\"\"Create the TINN model architecture.\"\"\"\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    # Input layer\n",
        "    model.add(tf.keras.Input(shape=(2,)))\n",
        "\n",
        "    # Hidden layers\n",
        "    for _ in range(num_hidden_layers - 1):\n",
        "        model.add(tf.keras.layers.Dense(\n",
        "            num_neurons_per_layer,\n",
        "            activation=tf.keras.activations.get('tanh'),\n",
        "            kernel_initializer='glorot_normal'\n",
        "        ))\n",
        "\n",
        "    # Final hidden layer with softplus activation\n",
        "    model.add(tf.keras.layers.Dense(\n",
        "        num_neurons_per_layer,\n",
        "        activation='softplus'\n",
        "    ))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(tf.keras.layers.Dense(1))\n",
        "\n",
        "    return model\n",
        "\n",
        "def compute_pde_residual(model, X_r):\n",
        "    \"\"\"Compute the PDE residual using automatic differentiation.\"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        # Split inputs\n",
        "        t, x = X_r[:, 0:1], X_r[:, 1:2]\n",
        "\n",
        "        # Watch variables for gradient computation\n",
        "        tape.watch(t)\n",
        "        tape.watch(x)\n",
        "\n",
        "        # Compute solution\n",
        "        u = model(tf.stack([t[:, 0], x[:, 0]], axis=1))\n",
        "\n",
        "        # Compute first derivatives\n",
        "        u_x = tape.gradient(u, x)\n",
        "\n",
        "    # Compute higher derivatives\n",
        "    u_t = tape.gradient(u, t)\n",
        "    u_xx = tape.gradient(u_x, x)\n",
        "\n",
        "    del tape\n",
        "\n",
        "    return pde_residual(t, x, u, u_t, u_x, u_xx)\n",
        "\n",
        "# =============================================================================\n",
        "# Training Utilities\n",
        "# =============================================================================\n",
        "\n",
        "def compute_loss(model, X_r, X_data, u_data):\n",
        "    \"\"\"Compute the total loss function.\"\"\"\n",
        "    # PDE residual loss\n",
        "    r = compute_pde_residual(model, X_r)\n",
        "    phi_r = tf.reduce_mean(tf.square(r))\n",
        "\n",
        "    # Initial condition loss\n",
        "    u_pred_0 = model(X_data[0])\n",
        "    loss_ic = tf.reduce_mean(tf.square(u_data[0] - u_pred_0))\n",
        "\n",
        "    # Boundary condition loss\n",
        "    u_pred_1 = model(X_data[1])\n",
        "    loss_bc = tf.reduce_mean(tf.square(u_data[1] - u_pred_1))\n",
        "\n",
        "    # Total loss\n",
        "    total_loss = phi_r + loss_ic + loss_bc\n",
        "\n",
        "    return total_loss, phi_r, loss_ic, loss_bc\n",
        "\n",
        "def get_gradients(model, X_r, X_data, u_data):\n",
        "    \"\"\"Compute gradients of the loss function.\"\"\"\n",
        "    with tf.GradientTape(persistent=True) as tape:\n",
        "        loss, loss_pde, loss_ic, loss_bc = compute_loss(\n",
        "            model, X_r, X_data, u_data)\n",
        "\n",
        "    gradients = tape.gradient(loss, model.trainable_variables)\n",
        "    del tape\n",
        "\n",
        "    return loss, gradients, loss_pde, loss_ic, loss_bc\n",
        "\n",
        "def setup_optimizer():\n",
        "    \"\"\"Setup the optimizer with learning rate schedule.\"\"\"\n",
        "    lr_schedule = tf.keras.optimizers.schedules.PiecewiseConstantDecay(\n",
        "        [1000, 5000, 20000],\n",
        "        [1e-2, 1e-3, 5e-4, 1e-4]\n",
        "    )\n",
        "    return tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "\n",
        "@tf.function\n",
        "def train_step(model, X_r, X_data, u_data, optimizer):\n",
        "    \"\"\"Single training step.\"\"\"\n",
        "    loss, gradients, loss_pde, loss_ic, loss_bc = get_gradients(\n",
        "        model, X_r, X_data, u_data)\n",
        "\n",
        "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
        "\n",
        "    return loss, loss_pde, loss_ic, loss_bc\n",
        "\n",
        "def train_model(model, X_r, X_data, u_data):\n",
        "    \"\"\"Train the TINN model.\"\"\"\n",
        "    optimizer = setup_optimizer()\n",
        "\n",
        "    # History tracking\n",
        "    history = {\n",
        "        'total_loss': [],\n",
        "        'pde_loss': [],\n",
        "        'ic_loss': [],\n",
        "        'bc_loss': []\n",
        "    }\n",
        "\n",
        "    print(\"Starting TINN training...\")\n",
        "    t0 = time()\n",
        "\n",
        "    for epoch in range(NUM_EPOCHS + 1):\n",
        "        loss, loss_pde, loss_ic, loss_bc = train_step(\n",
        "            model, X_r, X_data, u_data, optimizer)\n",
        "\n",
        "        # Store history\n",
        "        history['total_loss'].append(loss.numpy())\n",
        "        history['pde_loss'].append(loss_pde.numpy())\n",
        "        history['ic_loss'].append(loss_ic.numpy())\n",
        "        history['bc_loss'].append(loss_bc.numpy())\n",
        "\n",
        "        # Print progress\n",
        "        if epoch % 50 == 0:\n",
        "            print(f'Epoch {epoch:05d}: Loss = {loss.numpy():10.8e}')\n",
        "\n",
        "    training_time = time() - t0\n",
        "    print(f'\\nTraining completed in {training_time:.2f} seconds')\n",
        "\n",
        "    return history\n",
        "\n",
        "# =============================================================================\n",
        "# Finite Difference Solver\n",
        "# =============================================================================\n",
        "\n",
        "def tridiag(a, b, c, k1=-1, k2=0, k3=1):\n",
        "    \"\"\"Create tridiagonal matrix.\"\"\"\n",
        "    return np.diag(a, k1) + np.diag(b, k2) + np.diag(c, k3)\n",
        "\n",
        "def finite_difference_solver():\n",
        "    \"\"\"Solve the PDE using finite difference method for validation.\"\"\"\n",
        "    # Parameters\n",
        "    N = 500       # Number of spatial points\n",
        "    T = 3         # Total time\n",
        "    dt = 0.03     # Time step\n",
        "\n",
        "    # Spatial grid\n",
        "    x = np.linspace(-2, 2, N)\n",
        "    dx = x[1] - x[0]\n",
        "\n",
        "    # Initial condition: Gaussian distribution\n",
        "    P = 1 / (2 * np.sqrt(np.pi * DELTA)) * np.exp(-((x - 0.0)**2) / (4 * DELTA))\n",
        "\n",
        "    # Time evolution\n",
        "    timesteps = int(T / dt)\n",
        "    P_all = np.zeros((N, timesteps + 1))\n",
        "    P_all[:, 0] = P\n",
        "\n",
        "    for t in range(timesteps):\n",
        "        P_new = np.zeros_like(P)\n",
        "        tt = t * dt\n",
        "\n",
        "        # Construct matrices for Crank-Nicolson scheme\n",
        "        a = (-dt/(4 * dx**2) - (time_dependent_drift(tt) * dt)/(4 * dx)) * np.ones((N - 1))\n",
        "        b = (1 + (dt/(2 * dx**2))) * np.ones((N))\n",
        "        c = (-dt/(4 * dx**2) + (time_dependent_drift(tt) * dt)/(4 * dx)) * np.ones((N - 1))\n",
        "        A = tridiag(a, b, c)\n",
        "\n",
        "        aa = (dt/(4 * dx**2) + (time_dependent_drift(tt) * dt)/(4 * dx)) * np.ones((N - 1))\n",
        "        bb = (1 - (dt/(2 * dx**2))) * np.ones((N))\n",
        "        cc = (dt/(4 * dx**2) - (time_dependent_drift(tt) * dt)/(4 * dx)) * np.ones((N - 1))\n",
        "        B = tridiag(aa, bb, cc)\n",
        "\n",
        "        # Solve system\n",
        "        P_new = np.linalg.inv(A) @ B @ P\n",
        "\n",
        "        # Apply boundary conditions (Dirichlet)\n",
        "        P_new[0] = 0\n",
        "        P_new[-1] = 0\n",
        "\n",
        "        P = P_new\n",
        "        P_all[:, t + 1] = P\n",
        "\n",
        "    return P_all, x\n",
        "\n",
        "# =============================================================================\n",
        "# First Passage Time Analysis\n",
        "# =============================================================================\n",
        "\n",
        "def compute_first_passage_time_tinn(model, lb, ub, N=100):\n",
        "    \"\"\"Compute first passage time using TINN solution.\"\"\"\n",
        "    tspace = np.linspace(0, ub[0], N + 1)\n",
        "\n",
        "    # Points at boundary for finite difference\n",
        "    xspace = np.ones((N + 1)) * ub[1]\n",
        "    X = np.zeros((N + 1, 2))\n",
        "    X[:, 0] = tspace\n",
        "    X[:, 1] = xspace\n",
        "    X = tf.constant(X, DTYPE)\n",
        "    p_i = model(X)\n",
        "\n",
        "    # Points slightly inside for derivative calculation\n",
        "    xspace1 = np.ones((N + 1)) * (ub[1] - 0.02)\n",
        "    X1 = np.zeros((N + 1, 2))\n",
        "    X1[:, 0] = tspace\n",
        "    X1[:, 1] = xspace1\n",
        "    X1 = tf.constant(X1, DTYPE)\n",
        "    p_ii = model(X1)\n",
        "\n",
        "    xspace2 = np.ones((N + 1)) * (ub[1] - 0.04)\n",
        "    X2 = np.zeros((N + 1, 2))\n",
        "    X2[:, 0] = tspace\n",
        "    X2[:, 1] = xspace2\n",
        "    X2 = tf.constant(X2, DTYPE)\n",
        "    p_iii = model(X2)\n",
        "\n",
        "    # Compute spatial derivative using finite differences\n",
        "    p_x = (3 * p_i - 4 * p_ii + p_iii) / (2 * 0.02)\n",
        "\n",
        "    # Compute first passage time\n",
        "    J1 = np.reshape(time_dependent_drift(tspace), (N + 1, 1)) * p_i - 0.5 * SIGMA**2 * p_x\n",
        "\n",
        "    return J1.numpy().flatten(), tspace\n",
        "\n",
        "def compute_first_passage_time_fd(P_all, tspace):\n",
        "    \"\"\"Compute first passage time using finite difference solution.\"\"\"\n",
        "    N = len(tspace) - 1\n",
        "    # Compute spatial derivative at boundary using finite differences\n",
        "    p_x_fd = (3 * P_all[-1, :] - 4 * P_all[-2, :] + P_all[-3, :]) / (2 * 0.02)\n",
        "\n",
        "    # Compute first passage time\n",
        "    J1_fd = (np.reshape(time_dependent_drift(tspace), (1, N + 1)) *\n",
        "             P_all[-1, :] - 0.5 * SIGMA**2 * p_x_fd)\n",
        "\n",
        "    return J1_fd.flatten()\n",
        "\n",
        "# =============================================================================\n",
        "# Visualization Functions\n",
        "# =============================================================================\n",
        "\n",
        "def plot_training_history(history):\n",
        "    \"\"\"Plot the training loss history.\"\"\"\n",
        "    plt.figure(figsize=(10, 8))\n",
        "\n",
        "    plt.plot(history['total_loss'][100:], label='Total loss',\n",
        "             color='black', linestyle='-')\n",
        "    plt.plot(history['ic_loss'][100:], label='Initial loss',\n",
        "             color='black', linestyle='--')\n",
        "    plt.plot(history['bc_loss'][100:], label='Boundary loss',\n",
        "             color='black', linestyle='-.')\n",
        "    plt.plot(history['pde_loss'][100:], label='Theoretical loss',\n",
        "             color='black', linestyle=':')\n",
        "\n",
        "    plt.xlabel('Number of iterations', fontsize=16)\n",
        "    plt.ylabel('MSE', fontsize=16)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "    plt.legend(fontsize=14)\n",
        "    plt.savefig(\"loss_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_solution_comparison(model, P_all, x, lb, ub):\n",
        "    \"\"\"Plot comparison between TINN and FD solutions at different time points.\"\"\"\n",
        "    font = {\n",
        "        'family': 'serif',\n",
        "        'color': 'black',\n",
        "        'weight': 'normal',\n",
        "        'size': 17,\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(12, 8), dpi=90)\n",
        "\n",
        "    # FD solutions\n",
        "    plt.plot(x, P_all[:, 17], label='t = 0.5 (FD method)',\n",
        "             color='black', linestyle='-')\n",
        "    plt.plot(x, P_all[:, 34], label='t = 1.0 (FD method)',\n",
        "             color='black', linestyle='--')\n",
        "    plt.plot(x, P_all[:, -1], label='t = 3.0 (FD method)',\n",
        "             color='black', linestyle='-.')\n",
        "\n",
        "    # TINN solutions\n",
        "    t_list = [0.5, 1.0, 3.0]\n",
        "    labels = ['t = 0.5 (Presented method)',\n",
        "              't = 1.0 (Presented method)',\n",
        "              't = 3.0 (Presented method)']\n",
        "    markers = ['o', 's', '^']  # circle, square, triangle\n",
        "\n",
        "    for t_val, label, marker in zip(t_list, labels, markers):\n",
        "        N_points = 100\n",
        "        xspace = np.linspace(lb[1], ub[1], N_points + 1)\n",
        "        T_grid, X_grid = np.meshgrid(t_val, xspace)\n",
        "        Xgrid = np.vstack([T_grid.flatten(), X_grid.flatten()]).T\n",
        "\n",
        "        # Model prediction\n",
        "        upred = model(tf.cast(Xgrid, DTYPE))\n",
        "\n",
        "        # Plot\n",
        "        plt.scatter(X_grid, upred, label=label,\n",
        "                    color='black', marker=marker)\n",
        "\n",
        "    plt.xlabel('x', fontdict=font)\n",
        "    plt.ylabel('Probability', fontdict=font)\n",
        "    plt.legend(fontsize=18)\n",
        "    plt.tick_params(axis='both', labelsize=16)\n",
        "    plt.tight_layout()\n",
        "    plt.savefig(\"solution_comparison.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "def plot_first_passage_time_comparison(J1_tinn, J1_fd, tspace):\n",
        "    \"\"\"Plot comparison between TINN and FD first passage times.\"\"\"\n",
        "    font = {\n",
        "        'family': 'serif',\n",
        "        'color': 'black',\n",
        "        'weight': 'normal',\n",
        "        'size': 16,\n",
        "    }\n",
        "\n",
        "    plt.figure(figsize=(12, 8), dpi=90)\n",
        "\n",
        "    plt.scatter(tspace, J1_tinn, label='Approximated',\n",
        "                color='black', marker='o')\n",
        "    plt.plot(tspace, J1_fd.reshape((len(tspace), 1)), label='Exact',\n",
        "             color='black', linestyle='--')\n",
        "\n",
        "    plt.xlabel('Time', fontdict=font)\n",
        "    plt.ylabel('First passage time', fontdict=font)\n",
        "    plt.legend(fontsize=18)\n",
        "    plt.tick_params(axis='both', which='major', labelsize=14)\n",
        "    plt.savefig(\"first_passage_time_comparison.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
        "    plt.show()\n",
        "\n",
        "# =============================================================================\n",
        "# Main Execution\n",
        "# =============================================================================\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main function to run the TINN training and analysis.\"\"\"\n",
        "\n",
        "    # Prepare training data\n",
        "    X_r, X_data, u_data, lb, ub = prepare_training_data()\n",
        "\n",
        "    # Create and train TINN model\n",
        "    model = create_model()\n",
        "    history = train_model(model, X_r, X_data, u_data)\n",
        "\n",
        "    # Generate training plot\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # Run finite difference solver for comparison\n",
        "    print(\"Running finite difference solver...\")\n",
        "    P_all, x = finite_difference_solver()\n",
        "    print(\"Finite difference solution completed.\")\n",
        "\n",
        "    # Plot solution comparison\n",
        "    plot_solution_comparison(model, P_all, x, lb, ub)\n",
        "\n",
        "    # Compute and compare first passage times\n",
        "    print(\"Computing first passage times...\")\n",
        "    J1_tinn, tspace = compute_first_passage_time_tinn(model, lb, ub, N=100)\n",
        "    J1_fd = compute_first_passage_time_fd(P_all, tspace)\n",
        "\n",
        "    # Plot comparison\n",
        "    plot_first_passage_time_comparison(J1_tinn, J1_fd, tspace)\n",
        "\n",
        "    print(\"Analysis completed successfully!\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "id": "_UAFbssIrDPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "shk68k5vsuwP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}